{
  "scalamaptojson": {
    "desc": "测试",
    "strategy": "spark",
    "algorithm": [],
    "ref": [
    ],
    "compositor": [
      {
        "name": "stream.sources.kafka",
        "desc": "下面三选一",
        "params": [
          {
            "desc": "测试方便",
            "format": "socket",
            "hostname": "127.0.0.1",
            "port": "9003",
            "outputTable": "test"
          },
          {
            "desc": "这个是Kafka的 receiver based 模式",
            "format": "kafka",
            "topics": "a,b",
            "zkQuorum": "127.0.0.1",
            "groupId": "your group id",
            "outputTable": "test"
          },
          {
            "desc": "这个是Kafka的 direct approach  模式",
            "format": "kafka",
            "topics": "a,b",
            "metadata.broker.list": "127.0.0.1",
            "outputTable": "test"
          },
        ]
      },
      {
        "name": "ss.sql",
        "params": [
          {
            "sql": "select split(content)[0] as a, split(content)[0] as b from test",
            "outputTableName": "test2"
          }
        ]
      },
      {
        "name": "stream.output.print",
        "desc": "如果你前面已经使用 insert into hive 这种，就不需要这一行了 或者使用 stream.output.carbondata 模块",
        "params": [
          {
          }
        ]
      }
    ],
    "configParams": {
    }
  }
}